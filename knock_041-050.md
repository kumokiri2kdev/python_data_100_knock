# 顧客の退会を予測する１０本ノック

## データの読み込み

### 'csv/customer_join.csv' を 'customer' に読み込め。

``` python
import pandas as pd

customer = pd.read_csv('csv/customer_join.csv')
```

### 'csv/use_log_months.csv' を uselog_months に読み込め。

``` python
uselog_months = pd.read_csv('csv/use_log_months.csv')
```

### uselog_months の各データに、１ヶ月前のデータを追加せよ

``` python
year_months = uselog_months['年月'].unique()
uselog = pd.DataFrame()

for i in range(1, len(year_months)):
  tmp = uselog_months[uselog_months['年月'] == year_months[i]]
  tmp.rename(columns={'count' : 'count_0'}, inplace=True)
  tmp_before = uselog_months[uselog_months['年月'] == year_months[i-1]]
  del tmp_before['年月']
  tmp_before.rename(columns={'count' : 'count_1'}, inplace=True)
  tmp = pd.merge(tmp, tmp_before, on= 'customer_id', how='left')
  uselog = pd.concat([uselog, tmp], ignore_index=True)

```

### uselog から、退会をしたユーザーの退会前月のデータを抜き出せ

``` python
exit_customer = customer[customer['is_deleted'] == 1]

exit_customer['exit_date'] = None
exit_customer['end_date'] = pd.to_datetime(exit_customer['end_date'])

from dateutil.relativedelta import relativedelta

for i in range(len(exit_customer)):
    exit_customer.iloc[i]['exit_date'] =
      exit_customer.iloc[i]['end_date'] -
      relativedelta(months=1)

exit_customer['年月'] = exit_customer['exit_date'].dt.strftime('%Y%m')

uselog['年月'] = uselog['年月'].astype('str')

exit_uselog = pd.merge(uselog, exit_customer, on=['customer_id', '年月'], how='left')
```

### 'exit_uselog' で、名前が欠損している行を省け。

``` python
exit_uselog = exit_uselog.dropna(subset=['name'])

```

### 同様のデータを、継続ユーザーに関しても作成せよ。

``` python
conti_customer = customer[customer['is_deleted'] != 1]

conti_uselog = pd.merge(uselog, conti_customer, on='customer_id', how='left')
conti_uselog = conti_uselog.dropna(subset=['name'])
```

### 'conti_uselog' のデータをシャッフルせよ。

``` python
conti_uselog = conti_uselog.sample(frac=1).reset_index(drop=True)
```

### 'conti_uselog' のから 'customer_id' をキーに重複データを削除せよ。

``` python
conti_uselog = conti_uselog.drop_duplicates(subset='customer_id')
```

### 'exit_uselog' と 'conti_uselog' を結合せよ。

``` python
predict_data = pd.concat([conti_uselog, exit_uselog], ignore_index=True)
```

### 作成した 'predict_data' に在籍期間のデータ 'period' を追加せよ。

``` python
predict_data['period'] = 0
predict_data['now_date'] = pd.to_datetime(predict_data['年月'], format='%Y%m')
predict_data['start_date'] = pd.to_datetime(predict_data['start_date'])

for i in range(len(predict_data)):
    delta = relativedelta(
      predict_data.iloc[i]['now_date'],
      predict_data.iloc[i]['start_date'])
    predict_data['period'][i] = int(delta.years * 12 + delta.months)

```

### 欠損値を確認せよ

``` python
predict_data.isna().sum()
```
```
年月                      0
customer_id             0
count_0                 0
count_1               220
name                    0
class                   0
gender                  0
start_date              0
end_date             2842
campaign_id             0
is_deleted              0
class_name              0
price                   0
campaign_name           0
mean                    0
median                  0
max                     0
min                     0
routine_flg             0
calc_date               0
membership_period       0
exit_date            2842
exit_month           2842
period                  0
now_date                0
dtype: int64

```

### 欠損値のうち 'count_1' を欠損してる列を削除せよ

``` python
predict_data = predict_data.dropna(subset=['count_1'])
```

### 'predict_data'　から 'campaign_name', 'class_name', 'gender', 'count_1', 'routine_flg', 'period', 'is_deleted' を抜き出せ。

``` python
predict_data = predict_data[[
  'campaign_name', 'class_name', 'gender',
  'count_1', 'routine_flg', 'period', 'is_deleted'
]]  
```

### 'predict_data' から ダミー変数を作成せよ
``` python
predict_data = pd.get_dummies(predict_data)
```

### 'predict_data' の column 'campaign_name_通常', 'class_name_ナイト', 'gender_M' を削除せよ

``` python
del predict_data['campaign_name_通常']   
del predict_data['class_name_ナイト']
del predict_data['gender_M']  
```

### predct_data から 退会者を取り出し、'exit_customer' へ取り出し、同数の継続者を 'conti_customer' へ取り出せ

``` python
exit_customer = predict_data[predict_data['is_deleted'] == 1]

conti_customer = predict_data[predict_data['is_deleted'] == 0].
  sample(len(exit_customer))
```

### 'exit_customer' と 'conti_customer' を連結し、'is_deleted' を 目的変数 y に取り出し、それ以外を 説明変数 X に取り出せ。

``` python
X = pd.concat([exit_customer, conti_customer],ignore_index=True)
y = X['is_deleted']
del X['is_deleted']
```

### X と y をそれぞれ、訓練データとテストデータに振り分けよ
``` python
import sklearn.model_selection

X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y)
```

### 決定木にてトレーニングを実施せよ
``` python
from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier(random_state=0)
model.fit(X_train, y_train)
```

```
DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort='deprecated',
                       random_state=0, splitter='best')
```

### 'X_test' により 退会者を予測せよ
``` python
y_test_pred = model.predict(X_test)
```
```
array([0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0.,
       0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
       0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,
       1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0.,
       0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
       1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
       0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
       1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.,
       0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,
       1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.,
       1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
       1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,
       0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.,
       0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,
       0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
       1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,
       0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
       0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
       0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
       0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,
       0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
       1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
       0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.,
       0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,
       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
       1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,
       0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
       0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,
       0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
       0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,
       1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
       0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,
       1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
       0., 0., 0.])
```

### 予測結果からと実際の値を比較する Data Frame を作成せよ。
``` python
results_test = pd.DataFrame({'y_test': y_test, 'y_test_pred': y_test_pred})  
```

```
      y_test  y_test_pred
2084     0.0          0.0
1264     0.0          0.0
653      1.0          1.0
2407     0.0          0.0
1868     0.0          0.0
...      ...          ...
614      1.0          1.0
383      1.0          1.0
2346     0.0          0.0
1463     0.0          0.0
978      1.0          0.0
```

### 正解率を求めよ
``` python
correct = len(results_test[results_test['y_test'] == results_test['y_test_pred']])

correct / len(results_test)
```

```
0.9219512195121952
```
ここでは、約 92パーセントとなっている。
結果は、シャッフルの内容により変化する。

### テストデータに対するスコアを算出せよ

``` python
model.score(X_test, y_test)
```
```
0.9219512195121952
```
これは先に求めた正解率と同じになるはず。

### トレーニングデータに対するスコアを算出せよ
``` python
model.score(X_train, y_train)
```
```
0.984264785675529
```
この場合、トレーニングとテストの差がありトレーニングのスコアが高いため「過学習気味」と言える。


### 決定木の深さを 5 に変更して、学習とテストの結果を比較せよ

``` python
model = DecisionTreeClassifier(random_state=0, max_depth=5)
model.fit(X_train, y_train)

model.score(X_test, y_test)
model.score(X_train, y_train)
```

```
0.9349593495934959

0.9435702658708627
```
こちらの方が、テストデータの正解率が高く、トレーニングとテストの差が少なく、より最適化されていると言える。

### モデルに寄与している変数を確認せよ

``` python
importance = pd.DataFrame({'feature_names': X.columns, 'coefficient': model.feature_importances_})
```

```
            feature_names  coefficient
0                 count_1     0.463357
1             routine_flg     0.157155
2                  period     0.371684
3  campaign_name_入会費半額     0.000000
4  campaign_name_入会費無料     0.006943
5    class_name_オールタイム     0.000690
6     class_name_デイタイム     0.000172
7                 gender_F     0.000000
```
この内容からは、一番大きく寄与しているのは、'count_1' で、2番目が 'period' ということになる。

### count_1 : 3, routine_flg : 1, perios : 10, campaign_name_入会費半額 : 1, class_name_オールタイム : 1, gender_F : 1 のデータの退会を予測せよ

``` python
input_data = [3, 1, 10, 0, 1, 1, 0, 1]

model.predict([input_data])
```

```
array([1.])
```
'1' なので、退会と予測される。

### このデータの場合にの、退会する確率と退会しない確率を求めよ。
``` python
model.predict_proba([input_data])
```

```
array([[0., 1.]])
```
このデータに関しては、 0% と 100% となった。
